{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "SlHADAO-FnQ_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LPPO2NYqJF8C",
    "outputId": "cee42c8a-03ab-4766-f405-22f9f945619c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 1.13.1+cpu CUDA None\n",
      "Device: cuda:0\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Mar_21_19:24:09_Pacific_Daylight_Time_2021\n",
      "Cuda compilation tools, release 11.3, V11.3.58\n",
      "Build cuda_11.3.r11.3/compiler.29745058_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, device(type='cpu'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "print('Device:', torch.device('cuda:0'))\n",
    "\n",
    "!nvcc --version\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available(), device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "U7EsH32EFnRA"
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "NUM_TARGETS= 2\n",
    "\n",
    "USER_PATHWAY  = [256, 128, 64]\n",
    "ITEM_PATHWAY = [256, 128, 64]\n",
    "COMBINED_PATHWAY = [256, 128, 64, 16]\n",
    "\n",
    "EMBED_DIM = 40\n",
    "NUM_ITEM_EMBED = 5850\n",
    "NUM_USER_EMBED = 105571\n",
    "NUM_CUPSIZE_EMBED =  5\n",
    "NUM_CATEGORY_EMBED = 68\n",
    "\n",
    "NUM_USER_NUMERIC = 6\n",
    "NUM_ITEM_NUMERIC = 1\n",
    "\n",
    "DROPOUT = 0.3\n",
    "\n",
    "EPOCHS = 2\n",
    "LR = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "BATCH_SIZE = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RentTheRunway(torch.utils.data.Dataset):\n",
    "    def __init__(self,datapath):\n",
    "        self.data = pd.read_csv(datapath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        r = self.data.iloc[idx,:]\n",
    "\n",
    "        return {\n",
    "            \"user_id\" : np.array(r['user_id'], dtype=np.int64),\n",
    "            \"cup_size\" : np.array(r['rating']/2-1, dtype=np.int64),\n",
    "            \"user_numeric\" : np.array([r['bust size'], r['weight'], r['height'], r['age'], r['rented_int'], r['bodytype_int']], dtype=np.float32),\n",
    "            \"item_id\" : np.array(r['item_id'], dtype = np.int64),\n",
    "            \"category\" :np.array(r['category_int']-1, dtype = np.int64),\n",
    "            \"item_numeric\" : np.array([r['size']], dtype=np.float32),\n",
    "            \"fit\" : np.array(r['fit'], dtype=np.int64)\n",
    "        }\n",
    "\n",
    "datasets = OrderedDict()\n",
    "splits = ['train', 'valid']\n",
    "datasets['train'] =  RentTheRunway(\"data/renttherunway_final_data_processed_train.csv\")\n",
    "datasets['valid'] =  RentTheRunway(\"data/renttherunway_final_data_processed_valid.csv\")\n",
    "datasets['test'] = RentTheRunway(\"data/renttherunway_final_data_processed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "0vxnymEpFnRD"
   },
   "outputs": [],
   "source": [
    "# macro - Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account\n",
    "# weighted - Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    "def compute_metrics(target, pred_probs, averaging = \"macro\"):\n",
    "\n",
    "    pred_labels = pred_probs.argmax(-1)\n",
    "    precision = metrics.precision_score(target, pred_labels, average=averaging)\n",
    "    recall = metrics.recall_score(target, pred_labels, average=averaging)\n",
    "    f1_score = metrics.f1_score(target, pred_labels, average=averaging)\n",
    "    accuracy = metrics.accuracy_score(target, pred_labels)\n",
    "    auc = metrics.roc_auc_score(target, pred_probs, average=averaging, multi_class=\"ovr\")\n",
    "\n",
    "    return precision, recall, f1_score, accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "yicAQXX996RY"
   },
   "outputs": [],
   "source": [
    "class Base(nn.Module):\n",
    "    def __init__(self, user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.user_pathway = user_pathway\n",
    "        self.item_pathway = item_pathway\n",
    "        self.combined_pathway = combined_pathway\n",
    "        self.embedding_dim = embed_dim\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_user_embed, embed_dim, max_norm=1.0 )\n",
    "        self.cup_size_embedding = nn.Embedding(num_cupsize_embed, embed_dim, max_norm=1.0 )\n",
    "        self.item_embedding = nn.Embedding(num_item_embed, embed_dim, max_norm=1.0 )\n",
    "        self.category_embedding = nn.Embedding(num_category_embed, embed_dim, max_norm=1.0 )\n",
    "\n",
    "\n",
    "    def forward(self, batch_input):\n",
    "        # Customer Pathway\n",
    "        user_emb = self.user_embedding(batch_input[\"user_id\"])\n",
    "        cup_size_emb = self.cup_size_embedding(batch_input[\"cup_size\"])\n",
    "        user_representation = torch.cat( [user_emb, cup_size_emb, batch_input[\"user_numeric\"]], dim=-1 )\n",
    "        user_representation = self.user_transform_blocks(user_representation)\n",
    "\n",
    "        # Article Pathway\n",
    "        item_emb = self.item_embedding(batch_input[\"item_id\"])\n",
    "        category_emb = self.category_embedding(batch_input[\"category\"])\n",
    "        item_representation = torch.cat( [item_emb, category_emb, batch_input[\"item_numeric\"]], dim=-1 )\n",
    "        item_representation = self.item_transform_blocks(item_representation)\n",
    "\n",
    "        # Combine the pathways\n",
    "        combined_representation = torch.cat( [user_representation, item_representation], dim=-1 )\n",
    "        combined_representation = self.combined_blocks(combined_representation)\n",
    "\n",
    "        # Output layer of logits\n",
    "        logits = self.hidden2output(combined_representation)\n",
    "        pred_probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        return logits, pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "PpthRqIj96RZ"
   },
   "outputs": [],
   "source": [
    "class SFNet(Base):\n",
    "    def __init__(self, user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout):\n",
    "        super().__init__(user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout)\n",
    "\n",
    "        # Customer pathway transformation  ==  user_embedding_dim + cup_size_embedding_dim + num_user_numeric_features\n",
    "        user_features_input_size = 2 * self.embedding_dim + NUM_USER_NUMERIC\n",
    "        self.user_pathway.insert(0, user_features_input_size)\n",
    "        self.user_transform_blocks = []\n",
    "        for i in range(1, len(self.user_pathway)):\n",
    "            self.user_transform_blocks.append( SkipBlock( self.user_pathway[i - 1], self.user_pathway[i] ) )\n",
    "            self.user_transform_blocks.append(nn.Dropout(DROPOUT))\n",
    "        self.user_transform_blocks = nn.Sequential(*self.user_transform_blocks)\n",
    "\n",
    "        # Article pathway transformation == item_embedding_dim + category_embedding_dim + num_item_numeric_features\n",
    "        item_features_input_size = 2 * self.embedding_dim + NUM_ITEM_NUMERIC\n",
    "        self.item_pathway.insert(0, item_features_input_size)\n",
    "        self.item_transform_blocks = []\n",
    "        for i in range(1, len(self.item_pathway)):\n",
    "            self.item_transform_blocks.append( SkipBlock( self.item_pathway[i - 1], self.item_pathway[i]) )\n",
    "            self.item_transform_blocks.append(nn.Dropout(DROPOUT))\n",
    "        self.item_transform_blocks = nn.Sequential(*self.item_transform_blocks)\n",
    "\n",
    "        # Combined top layer pathway\n",
    "        # u = output dim of user_transform_blocks, # t = output dim of item_transform_blocks\n",
    "        # Pathway combination through [u, t] # Hence, input dimension will be 2*dim(u)\n",
    "        combined_layer_input_size = 2 * self.user_pathway[-1]\n",
    "        self.combined_pathway.insert(0, combined_layer_input_size)\n",
    "        self.combined_blocks = []\n",
    "        for i in range(1, len(self.combined_pathway)):\n",
    "            self.combined_blocks.append( SkipBlock( self.combined_pathway[i - 1], self.combined_pathway[i]) )\n",
    "            self.combined_blocks.append(nn.Dropout(DROPOUT))\n",
    "        self.combined_blocks = nn.Sequential(*self.combined_blocks)\n",
    "\n",
    "        # Linear transformation from last hidden layer to output\n",
    "        self.hidden2output = nn.Linear(self.combined_pathway[-1], NUM_TARGETS)\n",
    "\n",
    "\n",
    "class SkipBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\" Skip Connection for feed-forward  - ResNet Block \"\"\"\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(input_dim, output_dim)\n",
    "        self.W2 = nn.Linear(output_dim, output_dim)\n",
    "        self.I = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"  z = ReLU(   W2( ReLU( W1(x))) + Projection(x))    \"\"\"\n",
    "        z = relu(self.W2(relu(self.W1(x))) + self.I(x))\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "nP3EpC5EFnRE"
   },
   "outputs": [],
   "source": [
    "class MLP(Base):\n",
    "    def __init__(self,user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout):\n",
    "        super().__init__(user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout)\n",
    "\n",
    "        # Customer pathway transformation  ==  user_embedding_dim + cup_size_embedding_dim + num_user_numeric_features\n",
    "        user_features_input_size = 2 * self.embedding_dim + NUM_USER_NUMERIC\n",
    "        self.user_pathway.insert(0, user_features_input_size)\n",
    "        self.user_transform_blocks = []\n",
    "        for i in range(1, len(self.user_pathway)):\n",
    "            self.user_transform_blocks.append( LinearBlock( self.user_pathway[i - 1], self.user_pathway[i] ) )\n",
    "        self.user_transform_blocks = nn.Sequential(*self.user_transform_blocks)\n",
    "\n",
    "        # Article pathway transformation == item_embedding_dim + category_embedding_dim + num_item_numeric_features\n",
    "        item_features_input_size = 2 * self.embedding_dim + NUM_ITEM_NUMERIC\n",
    "        self.item_pathway.insert(0, item_features_input_size)\n",
    "        self.item_transform_blocks = []\n",
    "        for i in range(1, len(self.item_pathway)):\n",
    "            self.item_transform_blocks.append( LinearBlock( self.item_pathway[i - 1], self.item_pathway[i])  )\n",
    "        self.item_transform_blocks = nn.Sequential(*self.item_transform_blocks)\n",
    "\n",
    "        # Combined top layer pathway\n",
    "        # u = output dim of user_transform_blocks, # t = output dim of item_transform_blocks\n",
    "        # Pathway combination through [u, t] # Hence, input dimension will be 4*dim(u)\n",
    "        combined_layer_input_size = 2 * self.user_pathway[-1]\n",
    "        self.combined_pathway.insert(0, combined_layer_input_size)\n",
    "        self.combined_blocks = []\n",
    "        for i in range(1, len(self.combined_pathway)):\n",
    "            self.combined_blocks.append( LinearBlock( self.combined_pathway[i - 1], self.combined_pathway[i]) )\n",
    "        self.combined_blocks = nn.Sequential(*self.combined_blocks)\n",
    "\n",
    "        # Linear transformation from last hidden layer to output\n",
    "        self.hidden2output = nn.Linear(self.combined_pathway[-1], NUM_TARGETS)\n",
    "\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\" Skip Connection for feed-forward  - ResNet Block \"\"\"\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"  z = ReLU(   W2( ReLU( W1(x))) + Projection(x))    \"\"\"\n",
    "        return relu(self.W1(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6QlmtdwFnRK",
    "outputId": "97a6415f-1198-408e-b2d8-ed5759920704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "MLP(\n",
      "  (user_embedding): Embedding(105571, 40, max_norm=1.0)\n",
      "  (cup_size_embedding): Embedding(5, 40, max_norm=1.0)\n",
      "  (item_embedding): Embedding(5850, 40, max_norm=1.0)\n",
      "  (category_embedding): Embedding(68, 40, max_norm=1.0)\n",
      "  (user_transform_blocks): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (W1): Linear(in_features=86, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (W1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (W1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (item_transform_blocks): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (W1): Linear(in_features=81, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (W1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (W1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (combined_blocks): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (W1): Linear(in_features=128, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (W1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (W1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "    (3): LinearBlock(\n",
      "      (W1): Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (hidden2output): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Number of model parameters: 4660578\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = MLP(USER_PATHWAY, ITEM_PATHWAY, COMBINED_PATHWAY, EMBED_DIM, NUM_ITEM_EMBED, NUM_USER_EMBED, NUM_CUPSIZE_EMBED, NUM_CATEGORY_EMBED, DROPOUT)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(model)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of model parameters: {total_params}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "loss_criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay= WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SN2h7vipFnRL",
    "outputId": "8ff9253e-ceb9-4206-eddb-3136fd607205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch Stats 0/1204, Loss=0.68\n",
      "TRAIN Batch Stats 100/1204, Loss=0.59\n",
      "TRAIN Batch Stats 200/1204, Loss=0.58\n",
      "TRAIN Batch Stats 300/1204, Loss=0.53\n",
      "TRAIN Batch Stats 400/1204, Loss=0.48\n",
      "TRAIN Batch Stats 500/1204, Loss=0.55\n",
      "TRAIN Batch Stats 600/1204, Loss=0.57\n",
      "TRAIN Batch Stats 700/1204, Loss=0.59\n",
      "TRAIN Batch Stats 800/1204, Loss=0.53\n",
      "TRAIN Batch Stats 900/1204, Loss=0.58\n",
      "TRAIN Batch Stats 1000/1204, Loss=0.54\n",
      "TRAIN Batch Stats 1100/1204, Loss=0.56\n",
      "TRAIN Batch Stats 1200/1204, Loss=0.59\n",
      "TRAIN Batch Stats 1203/1204, Loss=0.55\n",
      "TRAIN Epoch 1 / 2, Mean Total Loss 0.5554295778274536\n",
      "VALID Batch Stats 0/157, Loss=0.61\n",
      "VALID Batch Stats 100/157, Loss=0.55\n",
      "VALID Batch Stats 156/157, Loss=0.56\n",
      "VALID Epoch 1 / 2, Mean Total Loss 0.5460434556007385\n",
      "TRAIN Batch Stats 0/1204, Loss=0.50\n",
      "TRAIN Batch Stats 100/1204, Loss=0.52\n",
      "TRAIN Batch Stats 200/1204, Loss=0.52\n",
      "TRAIN Batch Stats 300/1204, Loss=0.52\n",
      "TRAIN Batch Stats 400/1204, Loss=0.55\n",
      "TRAIN Batch Stats 500/1204, Loss=0.57\n",
      "TRAIN Batch Stats 600/1204, Loss=0.56\n",
      "TRAIN Batch Stats 700/1204, Loss=0.57\n",
      "TRAIN Batch Stats 800/1204, Loss=0.48\n",
      "TRAIN Batch Stats 900/1204, Loss=0.57\n",
      "TRAIN Batch Stats 1000/1204, Loss=0.53\n",
      "TRAIN Batch Stats 1100/1204, Loss=0.50\n",
      "TRAIN Batch Stats 1200/1204, Loss=0.57\n",
      "TRAIN Batch Stats 1203/1204, Loss=0.33\n",
      "TRAIN Epoch 1 / 2, Mean Total Loss 0.5247099995613098\n",
      "VALID Batch Stats 0/157, Loss=0.58\n",
      "VALID Batch Stats 100/157, Loss=0.53\n",
      "VALID Batch Stats 156/157, Loss=0.57\n",
      "VALID Epoch 1 / 2, Mean Total Loss 0.5142168402671814\n",
      "TRAIN Batch Stats 0/1204, Loss=0.56\n",
      "TRAIN Batch Stats 100/1204, Loss=0.46\n",
      "TRAIN Batch Stats 200/1204, Loss=0.56\n",
      "TRAIN Batch Stats 300/1204, Loss=0.44\n",
      "TRAIN Batch Stats 400/1204, Loss=0.49\n",
      "TRAIN Batch Stats 500/1204, Loss=0.52\n",
      "TRAIN Batch Stats 600/1204, Loss=0.45\n",
      "TRAIN Batch Stats 700/1204, Loss=0.56\n",
      "TRAIN Batch Stats 800/1204, Loss=0.55\n",
      "TRAIN Batch Stats 900/1204, Loss=0.47\n",
      "TRAIN Batch Stats 1000/1204, Loss=0.54\n",
      "TRAIN Batch Stats 1100/1204, Loss=0.57\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "\n",
    "tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    for d in datasets:\n",
    "        for split in splits:\n",
    "            data_loader = DataLoader( dataset=datasets[split], batch_size=BATCH_SIZE, shuffle = (split == \"train\") )\n",
    "\n",
    "            loss_tracker = defaultdict(tensor)\n",
    "\n",
    "            # Enable/Disable Dropout\n",
    "            if split == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                target_tracker = []\n",
    "                pred_tracker = []\n",
    "\n",
    "            for iteration, batch in enumerate(data_loader):\n",
    "\n",
    "                for k, v in batch.items():\n",
    "                    batch[k] = v.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits, pred_probs = model(batch)\n",
    "\n",
    "                # loss calculation\n",
    "                loss = loss_criterion(logits, batch[\"fit\"])   # batch['fit'] are the true labels\n",
    "\n",
    "                # backward + optimization\n",
    "                if split == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    step += 1\n",
    "\n",
    "                # bookkeepeing\n",
    "                loss_tracker[\"Total Loss\"] = torch.cat((loss_tracker[\"Total Loss\"], loss.view(1)))\n",
    "\n",
    "                if iteration % 100 == 0 or iteration + 1 == len(data_loader):\n",
    "                    print(f\"{split.upper()} Batch Stats {iteration}/{len(data_loader)}, Loss={loss.item() :.2f}\")\n",
    "\n",
    "                if split == \"valid\":\n",
    "                    target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
    "                    pred_tracker.append(pred_probs.cpu().data.numpy())\n",
    "\n",
    "            print( f\"{split.upper()} Epoch {epoch + 1} / {EPOCHS}, Mean Total Loss {torch.mean(loss_tracker['Total Loss'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VopBWrV5FnRM",
    "outputId": "f3856a2d-9d39-41b7-b0aa-6158df08ba8f"
   },
   "outputs": [],
   "source": [
    "target_tracker = []\n",
    "pred_tracker = []\n",
    "\n",
    "print(\"Preparing test data ...\")\n",
    "\n",
    "data_loader = DataLoader(dataset = datasets['test'], batch_size = BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Evaluating model on test data ...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for iteration, batch in enumerate(data_loader):\n",
    "\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        _, pred_probs = model(batch)\n",
    "\n",
    "        target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
    "        pred_tracker.append(pred_probs.cpu().data.numpy())\n",
    "\n",
    "target_tracker = np.stack(target_tracker[:-1]).reshape(-1)\n",
    "pred_tracker = np.stack(pred_tracker[:-1], axis=0).reshape(-1, NUM_TARGETS)\n",
    "precision, recall, f1_score, accuracy, auc = compute_metrics(target_tracker, pred_tracker, averaging = \"weighted\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Metrics:\\n Precision = {precision}\\n Recall = {recall}\\n F1-score = {f1_score}\\n Accuracy = {accuracy}\\n AUC = {auc}\\n \")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVl5-Yfs96Rc",
    "outputId": "086fb05e-46a4-439c-d5ab-1fb51398dab6"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "model = SFNet(USER_PATHWAY, ITEM_PATHWAY, COMBINED_PATHWAY, EMBED_DIM, NUM_ITEM_EMBED, NUM_USER_EMBED, NUM_CUPSIZE_EMBED, NUM_CATEGORY_EMBED, DROPOUT)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(model)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of model parameters: {total_params}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "loss_criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay= WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gon_ggoD96Rd",
    "outputId": "a8ed87e8-b9cc-4ced-d8e8-7b6dd4761aab"
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "\n",
    "tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    for d in datasets:\n",
    "        for split in splits:\n",
    "            data_loader = DataLoader( dataset=datasets[split], batch_size=BATCH_SIZE, shuffle = (split == \"train\") )\n",
    "\n",
    "            loss_tracker = defaultdict(tensor)\n",
    "\n",
    "            # Enable/Disable Dropout\n",
    "            if split == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                target_tracker = []\n",
    "                pred_tracker = []\n",
    "\n",
    "            for iteration, batch in enumerate(data_loader):\n",
    "\n",
    "                for k, v in batch.items():\n",
    "                    batch[k] = v.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                logits, pred_probs = model(batch)\n",
    "\n",
    "                # loss calculation\n",
    "                loss = loss_criterion(logits, batch[\"fit\"])   # batch['fit'] are the true labels\n",
    "\n",
    "                # backward + optimization\n",
    "                if split == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    step += 1\n",
    "\n",
    "                # bookkeepeing\n",
    "                loss_tracker[\"Total Loss\"] = torch.cat((loss_tracker[\"Total Loss\"], loss.view(1)))\n",
    "\n",
    "                if iteration % 100 == 0 or iteration + 1 == len(data_loader):\n",
    "                    print(f\"{split.upper()} Batch Stats {iteration}/{len(data_loader)}, Loss={loss.item() :.2f}\")\n",
    "\n",
    "                if split == \"valid\":\n",
    "                    target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
    "                    pred_tracker.append(pred_probs.cpu().data.numpy())\n",
    "\n",
    "            print( f\"{split.upper()} Epoch {epoch + 1} / {EPOCHS}, Mean Total Loss {torch.mean(loss_tracker['Total Loss'])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfZJOYqG96Rd",
    "outputId": "5932e070-1ed1-466b-a1a5-b7274e2386a7"
   },
   "outputs": [],
   "source": [
    "target_tracker = []\n",
    "pred_tracker = []\n",
    "\n",
    "print(\"Preparing test data ...\")\n",
    "\n",
    "data_loader = DataLoader(dataset = datasets['test'], batch_size = BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Evaluating model on test data ...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for iteration, batch in enumerate(data_loader):\n",
    "\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        _, pred_probs = model(batch)\n",
    "\n",
    "        target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
    "        pred_tracker.append(pred_probs.cpu().data.numpy())\n",
    "\n",
    "target_tracker = np.stack(target_tracker[:-1]).reshape(-1)\n",
    "pred_tracker = np.stack(pred_tracker[:-1], axis=0).reshape(-1, NUM_TARGETS)\n",
    "precision, recall, f1_score, accuracy, auc = compute_metrics(target_tracker, pred_tracker, averaging = \"weighted\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Metrics:\\n Precision = {precision}\\n Recall = {recall}\\n F1-score = {f1_score}\\n Accuracy = {accuracy}\\n AUC = {auc}\\n \")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1e5d2acd1631045f09d34790d51dde8c5f13a0de3f2ba4add1e385dbc0b204e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
